# camAD

This repository contains source codes and training models, but the experiment data please refer to the ADNI official website( https://adni.loni.usc.edu/).

## Introduce
We provided a medical image multimodal representation and fusion model named camAD based on MRI and PET scans for Alzheimer's disease (AD) early diagnosis, which used multiscale convolution to extract single-modality's features and cross attention to complement and fuse two modalities features. Compare with the existing models, camAD achieves superior performance with fewer pre-processing steps. 

Using the Alzheimerâ€™s disease neuroimaging initiative (ADNI) datasets, we demonstrate that integrating multi-modality data outperforms single modality models in terms of accuracy, specificity, sensitivity, AUC, and F1 scores. 

